{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_pheno = '/data1/guilimin/simons_vip/pheno/dataset.csv'\n",
    "match_pheno = '/data1/guilimin/simons_vip/pheno/dataset_good_16p.csv'\n",
    "raw_path = '/data1/guilimin/simons_vip/scores/scores_11_07/rmap_part/'\n",
    "all_pheno = '/data1/guilimin/simons_vip/pheno/dataset_16p_all.csv'\n",
    "all_s1 = '/data1/guilimin/simons_vip/pheno/dataset_16p_session1.csv'\n",
    "all_s2 = '/data1/guilimin/simons_vip/pheno/dataset_16p_session2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv(base_pheno, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = pd.read_csv(match_pheno, delimiter=';')\n",
    "match.rename(columns={'Unnamed: 0':'Subject'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base.ID = base.ID.str.replace(('.x'), ('x'))\n",
    "base.rename(columns={'FD.':'FD', 'frames_OK.':'frames_OK'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(base, match, on='ID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropcols = [s for s in merged.columns if \"_y\" in s]\n",
    "for colname in dropcols:\n",
    "    merged.drop(colname, axis=1, inplace=True)\n",
    "\n",
    "xcols = [s for s in merged.columns if \"_x\" in s]\n",
    "rename_dict = dict()\n",
    "for x in xcols:\n",
    "    news = x.split('_x')[0]\n",
    "    rename_dict[x] = news\n",
    "\n",
    "merged.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s14732xx6xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14786xx24xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14792xx10xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14806xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14858xx4xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14861xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14912xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14930xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14938xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14951xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14967xx25xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14976xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14979xx2xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14985xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s14992xx2xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n",
      "s15060xx1xFCAP1_session2_rest_rmap_part.nii.gz does not exist, drop em\n"
     ]
    }
   ],
   "source": [
    "# Check that the files exist\n",
    "drop = list()\n",
    "for ind, row in merged.iterrows():\n",
    "    if row.session == 'session1':\n",
    "        drop.append(ind)\n",
    "        continue\n",
    "    # File that we look for:\n",
    "    fname = '{}_rmap_part.nii.gz'.format(row.IID.strip(' '))\n",
    "    # Path that we are looking for\n",
    "    fpath = os.path.join(raw_path, fname)\n",
    "    # Does the file exist\n",
    "    if not os.path.isfile(fpath):\n",
    "        print('{} does not exist, drop em'.format(fname))\n",
    "        drop.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surchs/Venv/py35/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Correct some things in merged\n",
    "# Relabel the genetic column to numeric\n",
    "merged.genetic.replace({'deletion':1, 'non-familial0control':2, 'duplication':3, 'triplication': 3}, inplace=True)\n",
    "# Genetic status: NaN -> control, triplication -> duplication\n",
    "merged.genetic_status.replace({'triplication':'duplication'})\n",
    "merged.genetic_status[pd.isnull(merged.genetic_status)] = 'control'\n",
    "# Float columns with comma:\n",
    "corr_com = ['FD', 'FD_scrubbed', 'bmi', 'hc']\n",
    "\n",
    "for col in corr_com:\n",
    "    merged[col] = merged[col].str.replace(',', '.').astype(np.float)\n",
    "\n",
    "merged.rename(columns={'IID':''}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = merged.columns.tolist()\n",
    "new_cols = cols[1:] + cols[:1]\n",
    "merged = merged[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save merged\n",
    "merged.to_csv(all_pheno, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into sessions\n",
    "s1 = merged[merged.session=='session1']\n",
    "s2 = merged.drop(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1.to_csv(all_s1, index=False)\n",
    "s2.to_csv(all_s2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (v)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
